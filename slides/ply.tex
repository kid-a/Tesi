\section{PLY}

\subsection{Overview}
%------------------------------
\begin{frame}{Propylene and PLY}  
  %
  \begin{itemize}
    \item \navy{Propylene} is a Python classes generator:
\n
    %
    \begin{itemize}
      \item \textbf{Input:} a set of Profeta Plans (=the game strategy)
\n  
      \item \textbf{Output:} a set of subclasses of Profeta attitudes 
%\n  
%      \item \textbf{Tool:} we used \red{P}yton \red{L}ex-\red{Y}acc to
%      implement Propylene
    \end{itemize}
    %
\N
    \item \navy{Propylene} uses as parsing tool \red{PLY}, a pure-Python
    implementation of \emph{lex} and \emph{yacc}
    \item
     % \red{P}ython \red{L}ex-\red{Y}acc, 
\N\n
    \red{PLY} features include:
    %
    \begin{itemize}
%\n
      \item Support for SLR/LALR parsing
%\n  
%      \item Error checking, grammar validation
%\n  
      \item No need for a separate code-generation step
    \end{itemize}
    %
  \end{itemize}
  %
  \begin{quote}
    \begin{center}
      ``The main goal of Python Lex-Yacc is to stay faithful to the way in 
      which traditional lex/yacc tools work''
    \end{center}
  \end{quote}
  %
%
\N\N
\end{frame}
%------------------------------


\subsection{Lexer}
%------------------------------
\begin{frame}[fragile]{The \textbf{lex} Module}
  %
  \begin{itemize}
    \item \textbf{lex.py} breaks the input in tokens by using \emph{regular 
    expressions}
\n
    \item For simple rules, we can use Python raw string
    %
    \begin{itemize}
      \item \begin{verbatim} t_RANGLES = r'>>' \end{verbatim}
    \end{itemize}
    %
\n
    \item If some actions are needed, we can define a function
    %
    \begin{itemize}
      \item 
      \begin{verbatim} 
def t_newline(t):
    r'\n+'
    t.value = int(t.value) \end{verbatim}
    \end{itemize}
    %
\n
    \item All tokens are instances of \emph{LexToken} class, with attributes:
    %
    \begin{itemize}
      \item \emph{LexToken}.\textbf{type} \tab (e.g. STRING)
      \item \emph{LexToken}.\textbf{value} \tab (e.g. "left arm")
      \item \emph{LexToken}.\textbf{lineno} \tab the line at which the token 
      is found
      \item \emph{LexToken}.\textbf{lexpos} \tab the relative index in the stream of tokens
    \end{itemize}
    %
  \end{itemize}
  %
%
%
\N\N
\end{frame}


\subsection{Parser}
%------------------------------
\begin{frame}[fragile]{The \textbf{yacc} Module}
  %
  \begin{itemize}
    \item \textbf{yacc.py} implements the parsing component
\N
    \item Each grammar rule is defined by a Python function
\n
    \item The docstring contains the appropriate CFG specification
\n
    %
    \begin{itemize}
     \item 
      \begin{verbatim} 
def p_belief_event(p):
    ''' BeliefEvent : '+' Belief 
                    | '-' Belief ''' \end{verbatim}
    \end{itemize}
    %
\n
    \item The input argument \textbf{p} holds the values of grammar symbols
\n
    %
    \begin{itemize}
      \item 
      \begin{verbatim} 
def p_plan(p):
    ''' Plan : Head RANGLES Body ''' 
         ^      ^      ^     ^
       p[0]   p[1]   p[2]  p[3] \end{verbatim}
    \end{itemize}
    %
  \end{itemize}
  %
%
\N\N
\end{frame}


\subsection{Error Handling}
%------------------------------
\begin{frame}[fragile]{Error Handling}
  %
  \begin{itemize}
    \item When a \textbf{syntax error} occurs: 
    %
    \begin{itemize}
      \item The special \texttt{p\_error(p)} function is invoked;
      \item The offending token is replaced by the special \texttt{error} 
      token
      \item The parser attempts to reduce a rule involving \texttt{error}
    \end{itemize}
    %
\n
%%
\begin{exampleblock}{Error Rule Example}
\begin{verbatim}
def p_trigger_error(self, p):
    ``` Head : '(' error '|' Condition ')' '''
    print "Illegal Triggering Event"
\end{verbatim}
\end{exampleblock}
%%
\n
   \item The \texttt{error} token matches any bad input up to `\texttt{|}'
\n
    \item The tokens which follow \texttt{error} acts as \textbf{synch} 
    tokens

  \end{itemize}
  %
%
%
\N\N
\end{frame}



